{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Wavegan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Purpose:** \n",
    "The purpose of this WaveGan is to generate 1 second audio samples based on a ditribution of 1 second audio samples. This is achieved by using a generative adversarial network where a generator neural network and a discriminator neural network play a minimax game agasint one another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Setup:** \n",
    "A requirement for this program to work is to have audio split into 1 second samples in one folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure arguments for this network:\n",
    "`parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dataset_dir_x', dest='dataset_dir', default='formatteddata', help='path of the dataset')\n",
    "parser.add_argument('--output_dir_x', dest='output_dir', default='generatedaudio', help='path for generated output')\n",
    "parser.add_argument('--epoch', dest='epoch', type=int, default=200001, help='# of epoch')\n",
    "parser.add_argument('--epoch_step', dest='epoch_step', type=int, default=100, help='# of epoch to decay lr')\n",
    "parser.add_argument('--lamda', dest='lamda', type=int, default=10, help='Wasserstein Distance Multiplier')\n",
    "parser.add_argument('--generator_learning_rate', dest='glr', type=float, default=.0001,help=' generator learning rate')\n",
    "parser.add_argument('--discriminator_learning_rate', dest='dlr', type=float, default=.0001,help=' generator learning rate')\n",
    "parser.add_argument('--batch_size', dest='batch_size', type=int, default=64, help='# images in batch')\n",
    "parser.add_argument('--num_z_dims', dest='z_dims', type=int, default=5, help='dimensions in z')\n",
    "parser.add_argument('--num_critic_steps', dest='num_critic_steps', type=int, default=10, help='number of discriminator steps per generator step')\n",
    "parser.add_argument('--num_seconds', dest='num_seconds', type=int, default=4, help='amount of data in audio sample')\n",
    "parser.add_argument('--len_audio_sample', dest='a_len', type=int, default=16384*4, help='amount of data in audio sample')\n",
    "args = parser.parse_args()`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate and Train Wavegan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(config=tfconfig) as sess:\n",
    "        model = wavegan(sess, args)\n",
    "        model.train(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ### Initialize values for Wavegan\n",
    "    \n",
    "    def __init__(self, sess, args):\n",
    "        self.sess = sess\n",
    "        self.batch_size = args.batch_size\n",
    "        self.dataset_dir = args.dataset_dir\n",
    "        self.epoch=args.epoch\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.x_data= nnUtils.import_audio(self.dataset_dir)\n",
    "        self.x_data=util.scale_data(self.x_data)\n",
    "        self.output_dir=args.output_dir\n",
    "        self.a_len=args.a_len\n",
    "        self.glr=args.glr\n",
    "        self.dlr=args.dlr\n",
    "        self.num_seconds=args.num_seconds\n",
    "        self.z_dims=args.z_dims\n",
    "        self.lamda=args.lamda\n",
    "        self.num_critic_steps=args.num_critic_steps\n",
    "        self.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build(self) is called within the initialization of Wavegan and assembles the architecture for the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def build(self):\n",
    "        self.x=tf.placeholder(tf.float32, [None, self.a_len, 1])\n",
    "        self.z=tf.placeholder(tf.float32, [None, self.z_dims])\n",
    "\n",
    "        self.genx = generator(self.z, num_seconds=self.num_seconds)\n",
    "\n",
    "        self.rand = tf.random_uniform([tf.shape(self.x)[0]], minval=0, maxval=1)\n",
    "        self.interp = tf.transpose((self.rand * tf.transpose(self.x, [2, 1, 0])), \\\n",
    "                                [2,1,0]) + tf.transpose(((1 - self.rand) * \\\n",
    "                                tf.transpose(self.genx, [2,1,0])), [2,1,0])\n",
    "        self.Interpolator = discriminator(self.interp,name=\"GAN/discriminator\")\n",
    "        self.c_out_int = tf.reshape(self.Interpolator, [-1, 1])\n",
    "        self.c_grad_int = tf.gradients(self.c_out_int, self.interp)[0]\n",
    "        self.lag_int = tf.reduce_mean(tf.pow((tf.norm(self.c_grad_int, ord='euclidean', axis=(1, 2)) - 1), 2))\n",
    "        self.dx = discriminator(self.x, name=\"GAN/discriminator\", reuse=True)\n",
    "        self.dg = discriminator(self.genx, name=\"GAN/discriminator\",reuse=True)\n",
    "        self.wd = tf.reduce_mean(self.dx-self.dg)\n",
    "        self.d_loss = (self.lamda*self.lag_int)-self.wd\n",
    "        self.g_loss=self.wd\n",
    "        vars=tf.trainable_variables()\n",
    "        self.d_vars=[v for v in vars if (v.name.startswith(\"GAN/discriminator\"))]\n",
    "        self.g_vars=[v for v in vars if (v.name.startswith(\"gen\"))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate phi object and train \n",
    "`with tf.Session(config=tfconfig) as sess:\n",
    "        model = phi(sess, args)\n",
    "        model.train(args)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set arguments in phi object\n",
    "`def __init__(self, sess, args):\n",
    "        self.sess = sess\n",
    "        self.dataset_dir_x = args.dataset_dir_x\n",
    "        self.test_dir_x = args.test_dir_x\n",
    "        self.fig_output=args.fig_output\n",
    "        self.epoch = args.epoch\n",
    "        self.lr = args.lr\n",
    "        self.dataset_dir_x = args.dataset_dir_x\n",
    "        self.beta1 = args.beta1\n",
    "        self.image_shape = args.image_shape\n",
    "        self.batch_size = args.bs\n",
    "        self.phi_network = phi_network_residual\n",
    "        self.input= nnUtils.import_images(self.dataset_dir_x)\n",
    "        self.input_indecies=np.load(args.indecies_file)\n",
    "        self.num_bins=args.num_bins\n",
    "        self.alpha=args.alpha\n",
    "        self.vector_dims=args.vector_dims\n",
    "        self.graph = args.graph\n",
    "        self.graph_freq = args.graph_freq\n",
    "        self.graph_amount=args.graph_amount\n",
    "        self.plot_loss=args.plot_loss\n",
    "        self.solid_shapes = args.solid_shapes\n",
    "        self.plot3d=args.plot3d\n",
    "        self.build()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def train(self,args):\n",
    "        self.d_optim = tf.train.AdamOptimizer(self.dlr) \\\n",
    "            .minimize(self.d_loss, var_list=self.d_vars)\n",
    "        self.g_optim = tf.train.AdamOptimizer(self.glr) \\\n",
    "            .minimize(self.g_loss, var_list=self.g_vars)\n",
    "        iteration = tf.Variable(0, dtype=tf.int32)\n",
    "        increment_iter = tf.assign(iteration, iteration + 1)\n",
    "        init=tf.global_variables_initializer()\n",
    "        self.sess.run(init)\n",
    "        for i in range(self.epoch):\n",
    "            for j in range(int(self.x_data.shape[0]/self.batch_size)):\n",
    "                z_batch = np.random.randn(self.batch_size, self.z_dims)\n",
    "                randlist_x = np.random.randint(0, self.x_data.shape[0], self.batch_size)\n",
    "                real_x_sample=np.reshape(self.x_data,(self.x_data.shape[0],self.a_len,1))\n",
    "                real_x_sample=real_x_sample[randlist_x]\n",
    "                for k in range(self.num_critic_steps):\n",
    "                    # Update D network\n",
    "\n",
    "                    d_loss, _ = self.sess.run(\n",
    "                        [self.d_loss,self.d_optim],\n",
    "                        feed_dict={self.x: real_x_sample,\n",
    "                        self.z: z_batch})\n",
    "\n",
    "                #G Network\n",
    "                fake_x, _ = self.sess.run(\n",
    "                [self.genx, self.g_optim],\n",
    "                feed_dict={self.z: z_batch, self.x: real_x_sample})\n",
    "                wd=self.sess.run(self.wd, feed_dict={self.z: z_batch, self.x: real_x_sample})\n",
    "                dx=self.sess.run(self.dx, feed_dict={self.z: z_batch, self.x: real_x_sample})\n",
    "                dg=self.sess.run(self.dg, feed_dict={self.z: z_batch, self.x: real_x_sample})\n",
    "                print(\"Wasserstein Disctance: \" + str(wd))\n",
    "            print(\"Iterations: %d\\t\" %(i))\n",
    "            self.sess.run(increment_iter)\n",
    "            if (i%1==0):\n",
    "                g_batch = util.scale_data(fake_x, scale=[-32759, 32759], dtype=np.int32)\n",
    "                nnUtils.write_audio(g_batch[:10],self.output_dir,i)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
